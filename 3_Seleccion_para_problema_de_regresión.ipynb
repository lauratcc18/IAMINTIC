{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauratcc18/IAMINTIC/blob/main/3_Seleccion_para_problema_de_regresi%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selección de Características\n",
        "## Problema de regresión\n",
        "En este caso crearemos un dataset numérico tanto en variables de entrada como de salida para modelar un problema de regresión. Para ello usaremos la función make_regression().\n",
        "\n",
        "En un problema de regresión, se puede caluclar que tan fuerte es la relación entre cada entrada con la salida, midiendo su correlación y comparandola con la de las demás variables"
      ],
      "metadata": {
        "id": "CIumTrdLWIth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Crear el dataset\n",
        "La función make_regression() nos permite adicionalmente definir el número de muestras, cuántas características de entrada y cuántas de ellas son o no relevantes para la salida.\n",
        "\n",
        "En este caso crearemos un dataset con 1000 muestras y 100 atributos (10 relevantes y 90 irrelevantes) y lo dividiremos en sets de entrenamiento y pruebas para poder ajustar y evaluar el modelo de predicción."
      ],
      "metadata": {
        "id": "8FLaf78ZJnyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generar el dataset de regresion\n",
        "X, y = make_regression(n_samples=1000, n_features=100, n_informative=10, noise=0.1,\n",
        "random_state=1)\n",
        "\n",
        "# Dividirlo en sets de entrenamiento y pruebas\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n"
      ],
      "metadata": {
        "id": "RsyKkQpVme8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>Imprima cómo quedaron repartidos los valores entre los datasets (su forma) </B>\n",
        "\n",
        "<!-- Puede usar el siguiente código:\n",
        "\n",
        "# Mostrar estatus\n",
        "print('Train', X_train.shape, y_train.shape)\n",
        "print('Test', X_test.shape, y_test.shape)\n",
        "\n",
        "-->"
      ],
      "metadata": {
        "id": "mrviDxQBHPpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Digite su código aqui\n"
      ],
      "metadata": {
        "id": "LjrtZBlPHq6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Aplicar el método de selección de características\n",
        "Para datasets numéricos es común utilizar métodos de correlación estadística para seleccionar las características más relevantes. La correlación mide como dos variables cambian conjuntamente, es decir, que tan fuerte el cambio en una variable afecta a la segunda.\n",
        "\n",
        "Una de las más usadas en la correlación de Pearson que asume una distribución Gausiana en cada variable y reporta su relación lineal. El valor de correlación varía entre -1 y 1, donde el 0 significa que no hay correlación, el 1 una correlación directa y el -1 una correlación inversa.\n",
        "\n",
        "Para seleccionar características se manejan valores entre 0 y 1, buscando los que más se aproximen al 1.\n",
        "\n",
        "<B>Utilizando la función f_regression, aplique el método de selección de características para evaluar todos los atributos, de forma similar a como se realizó con chi2 y con mutual information. </B>\n",
        "\n",
        "<!-- Puede utilizar el siguiente código:\n",
        "\n",
        "# Selección de características con correlación estadística\n",
        "fs = SelectKBest(score_func=f_regression, k='all')\n",
        "fs.fit(X_train, y_train)\n",
        "X_train_fs = fs.transform(X_train)\n",
        "X_test_fs = fs.transform(X_test)\n",
        "\n",
        "-->\n"
      ],
      "metadata": {
        "id": "9mWkLXErPHwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_regression\n",
        "\n",
        "# Digite su código aqui:\n",
        "fs = SelectKBest(score_func=f_regression, k=\"all\")\n",
        "fs.fit(X_train, y_train)\n",
        "X_train_fs = fs.transform(X_train)\n",
        "X_test_fs = fs.transform(X_test)\n"
      ],
      "metadata": {
        "id": "OlsQ4eWO28_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>Imprima los puntajes de cada variable (entre más alto, mejor) y grafíquelos para darse una idea de cuántas características debería seleccionar.</B>\n",
        "\n",
        "<!-- Puede usar el siguiente código:\n",
        "\n",
        "# Puntajes de las características\n",
        "for i in range(len(fs.scores_)):\n",
        "\tprint('Atributo %d: %f' % (i, fs.scores_[i]))\n",
        "# Diagrama de puntajes\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "print()\n",
        "pyplot.show()\n",
        "\n",
        "-->"
      ],
      "metadata": {
        "id": "wPsGtzUZQeEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "# Digite su código aqui:\n",
        "# Puntajes de las características\n",
        "for i in range(len(fs.scores_)):\n",
        "\tprint('Atributo %d: %f' % (i, fs.scores_[i]))\n",
        "# Diagrama de puntajes\n",
        "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
        "print()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "w5kCxmk85Qwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "260e5d46-89eb-4113-bd30-3390fc7595c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Atributo 0: 0.009419\n",
            "Atributo 1: 1.018881\n",
            "Atributo 2: 1.205187\n",
            "Atributo 3: 0.000138\n",
            "Atributo 4: 0.167511\n",
            "Atributo 5: 5.985083\n",
            "Atributo 6: 0.062405\n",
            "Atributo 7: 1.455257\n",
            "Atributo 8: 0.420384\n",
            "Atributo 9: 101.392225\n",
            "Atributo 10: 0.387091\n",
            "Atributo 11: 1.581124\n",
            "Atributo 12: 3.014463\n",
            "Atributo 13: 0.232705\n",
            "Atributo 14: 0.076281\n",
            "Atributo 15: 4.299652\n",
            "Atributo 16: 1.497530\n",
            "Atributo 17: 0.261242\n",
            "Atributo 18: 5.960005\n",
            "Atributo 19: 0.523219\n",
            "Atributo 20: 0.003365\n",
            "Atributo 21: 0.024178\n",
            "Atributo 22: 0.220958\n",
            "Atributo 23: 0.576770\n",
            "Atributo 24: 0.627198\n",
            "Atributo 25: 0.350687\n",
            "Atributo 26: 0.281877\n",
            "Atributo 27: 0.584210\n",
            "Atributo 28: 52.196337\n",
            "Atributo 29: 0.046855\n",
            "Atributo 30: 0.147323\n",
            "Atributo 31: 0.368485\n",
            "Atributo 32: 0.077631\n",
            "Atributo 33: 0.698140\n",
            "Atributo 34: 45.744046\n",
            "Atributo 35: 2.047376\n",
            "Atributo 36: 0.786270\n",
            "Atributo 37: 0.996190\n",
            "Atributo 38: 2.733533\n",
            "Atributo 39: 63.957656\n",
            "Atributo 40: 231.885540\n",
            "Atributo 41: 1.372448\n",
            "Atributo 42: 0.581860\n",
            "Atributo 43: 1.072930\n",
            "Atributo 44: 1.066976\n",
            "Atributo 45: 0.344656\n",
            "Atributo 46: 13.951551\n",
            "Atributo 47: 3.575080\n",
            "Atributo 48: 0.007299\n",
            "Atributo 49: 0.004651\n",
            "Atributo 50: 1.094585\n",
            "Atributo 51: 0.241065\n",
            "Atributo 52: 0.355137\n",
            "Atributo 53: 0.020294\n",
            "Atributo 54: 0.154567\n",
            "Atributo 55: 2.592512\n",
            "Atributo 56: 0.300175\n",
            "Atributo 57: 0.357798\n",
            "Atributo 58: 3.060090\n",
            "Atributo 59: 0.890357\n",
            "Atributo 60: 122.132164\n",
            "Atributo 61: 2.029982\n",
            "Atributo 62: 0.091551\n",
            "Atributo 63: 1.081123\n",
            "Atributo 64: 0.056041\n",
            "Atributo 65: 2.930717\n",
            "Atributo 66: 0.054886\n",
            "Atributo 67: 1.332787\n",
            "Atributo 68: 0.145579\n",
            "Atributo 69: 0.986331\n",
            "Atributo 70: 0.092661\n",
            "Atributo 71: 0.083219\n",
            "Atributo 72: 0.198847\n",
            "Atributo 73: 2.065792\n",
            "Atributo 74: 0.236594\n",
            "Atributo 75: 0.512608\n",
            "Atributo 76: 1.095650\n",
            "Atributo 77: 0.015359\n",
            "Atributo 78: 2.193730\n",
            "Atributo 79: 1.574530\n",
            "Atributo 80: 5.360863\n",
            "Atributo 81: 0.041874\n",
            "Atributo 82: 5.717705\n",
            "Atributo 83: 0.436560\n",
            "Atributo 84: 5.594438\n",
            "Atributo 85: 0.000065\n",
            "Atributo 86: 0.026748\n",
            "Atributo 87: 0.408422\n",
            "Atributo 88: 2.092557\n",
            "Atributo 89: 9.568498\n",
            "Atributo 90: 0.642445\n",
            "Atributo 91: 0.065794\n",
            "Atributo 92: 198.705931\n",
            "Atributo 93: 0.073807\n",
            "Atributo 94: 1.048605\n",
            "Atributo 95: 0.004106\n",
            "Atributo 96: 0.042110\n",
            "Atributo 97: 0.034228\n",
            "Atributo 98: 0.792433\n",
            "Atributo 99: 0.015365\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los puntajes y la gráfica nos permiten elegir el valor más adecuado para k en SelectKBest."
      ],
      "metadata": {
        "id": "9cLPN5btSPZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Modelar\n",
        "Vamos a comparar los resultados que se obtendrían si se aplica un modelo de Regresión lineal que utilice todas las variables de entrada disponibles, contra el modelo con características seleccionadas por correlación estadística.\n",
        "\n",
        "####3.1 Modelo usando todas las características\n",
        "Inicialmente evaluamos el modelo LinearRegression con todas las características, entrenado en el dataset de entrenamiento y evaluado en el de pruebas."
      ],
      "metadata": {
        "id": "KDA8NzZ-a3m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Ajustar el modelo\n",
        "modeloRL = LinearRegression()\n",
        "modeloRL.fit(X_train, y_train)\n",
        "# Evaluar el modelo\n",
        "ypred = modeloRL.predict(X_test)\n",
        "# Evaluar la predicción\n",
        "error = mean_absolute_error(y_test, ypred)\n",
        "print('Error absoluto medio: %.3f' % error)"
      ],
      "metadata": {
        "id": "_NONmakwukqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc3cf6c-d4a4-47ef-b9b1-f3a72256e5e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error absoluto medio: 0.086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3.2 Modelo construido con correlación estadística\n",
        "Seleccionemos las 10 características más relevantes y generemos el modelo"
      ],
      "metadata": {
        "id": "WcIqNTqzw_t-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selección de top-10 caracterítsticas\n",
        "fs = SelectKBest(score_func=f_regression, k=10)\n",
        "fs.fit(X_train, y_train)\n",
        "X_train_fs = fs.transform(X_train)\n",
        "X_test_fs = fs.transform(X_test)\n",
        "\n",
        "# Ajustar el modelo\n",
        "modeloE = LinearRegression()\n",
        "modeloE.fit(X_train_fs, y_train)\n",
        "# Evaluar el modelo\n",
        "ypredE = modeloE.predict(X_test_fs)\n",
        "# Evaluar la predicción\n",
        "ErrorE = mean_absolute_error(y_test, ypredE)\n",
        "print('Error absoluto: %.3f' % ErrorE)"
      ],
      "metadata": {
        "id": "c2Gj2gxAxLOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3dcb48c-01b8-4c8d-a871-a6453e8ad9ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error absoluto: 2.740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>¿Qué conclusiones puede obtener de los resultados?\n",
        "\n",
        "¿Cómo varía el resultado con diferentes valores de k?.</B>"
      ],
      "metadata": {
        "id": "-XxnROuxtiWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Sintonizar el número de características (k)\n",
        "El objetivo es probar sistemáticamente diferentes valores para k, de forma que se descubra el valor que genera el mejor desempeño del modelo (grilla de búsqueda). Para ello se usa la función RepeatedKFold con 3 repeticiones y 10 grupos y se crea un pipeline que transforme el dataset de entrenamiento con las características seleccionadas y lo aplique a los sets de entrenamiento y prueba en cada validación cruzada."
      ],
      "metadata": {
        "id": "OgNtwCyyuSTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Definir el método de evaluación\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "# Definir pipeline para evaluar\n",
        "modelo = LinearRegression()\n",
        "fs = SelectKBest(score_func=f_regression)\n",
        "pipeline = Pipeline(steps=[('sel', fs), ('lr', modelo)])"
      ],
      "metadata": {
        "id": "0wRBRCoV8BRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posteriormente se define la grilla de búsqueda con valores entre 80 y 100 características (para ello se crea un diccionario donde en el nombre del objeto (sel__k) se cambiará el valor de k por cada valor buscado) y se ejecuta la búsqueda evaluando el modelo con el error absoluto medio negativo.\n",
        "\n",
        "En este caso se usa el errro absoluto medio negativo porque sklearn requiere que se maximice el puntaje y por ello el error se evalúa con valores entre -infinito y 0 (el mejor)."
      ],
      "metadata": {
        "id": "mlLXI35o9pyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definir la grilla\n",
        "grilla = dict()\n",
        "grilla['sel__k'] = [i for i in range(X.shape[1] - 20, X.shape[1] + 1)]\n",
        "\n",
        "# Definir la grilla de búsqueda\n",
        "busqueda = GridSearchCV(pipeline, grilla, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n",
        "\n",
        "# Ejecutar la búsqueda\n",
        "resultados = busqueda.fit(X,y)"
      ],
      "metadata": {
        "id": "iVVTwsku-ZaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente se procede a mostrar los resultados"
      ],
      "metadata": {
        "id": "wDo9dEXGAuMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resumir los mejores\n",
        "print('Mejores errores absolutos_ %.3f' % resultados.best_score_)\n",
        "print('Mejores configuraciones: %s' % resultados.best_params_)\n",
        "\n",
        "# Resumir todos\n",
        "medias = resultados.cv_results_['mean_test_score']\n",
        "parametros = resultados.cv_results_['params']\n",
        "for media, param in zip(medias, parametros):\n",
        "  print('Error %.3f con: %r' % (media, param))"
      ],
      "metadata": {
        "id": "2y2AeG1xAySQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864f9231-8b3c-42b4-c51c-b50eceecad1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores errores absolutos_ -0.083\n",
            "Mejores configuraciones: {'sel__k': 100}\n",
            "Error -2.324 con: {'sel__k': 80}\n",
            "Error -2.137 con: {'sel__k': 81}\n",
            "Error -1.958 con: {'sel__k': 82}\n",
            "Error -1.853 con: {'sel__k': 83}\n",
            "Error -1.756 con: {'sel__k': 84}\n",
            "Error -1.663 con: {'sel__k': 85}\n",
            "Error -1.667 con: {'sel__k': 86}\n",
            "Error -1.389 con: {'sel__k': 87}\n",
            "Error -1.016 con: {'sel__k': 88}\n",
            "Error -0.927 con: {'sel__k': 89}\n",
            "Error -0.928 con: {'sel__k': 90}\n",
            "Error -0.842 con: {'sel__k': 91}\n",
            "Error -0.842 con: {'sel__k': 92}\n",
            "Error -0.742 con: {'sel__k': 93}\n",
            "Error -0.743 con: {'sel__k': 94}\n",
            "Error -0.743 con: {'sel__k': 95}\n",
            "Error -0.650 con: {'sel__k': 96}\n",
            "Error -0.464 con: {'sel__k': 97}\n",
            "Error -0.372 con: {'sel__k': 98}\n",
            "Error -0.183 con: {'sel__k': 99}\n",
            "Error -0.083 con: {'sel__k': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<B>Repita el procedimiento anterior usando la función estadística mutual information (mutual_info_regression) que puede importar de sklearn.feature_selection, y observe los resultados.</B>"
      ],
      "metadata": {
        "id": "Lsqkoei8CzQh"
      }
    }
  ]
}