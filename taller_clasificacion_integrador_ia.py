# -*- coding: utf-8 -*-
"""taller_clasificacion_integrador_ia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/jofsanchezci/b0b2ab420129b7575e18711c6c3e99bc/taller_clasificacion_integrador_ia.ipynb

#Clasificaci칩n

Proyecto de clasificaci칩n, para diagnosticar medicamenttos bas치ndose en las caracteristicas de los pacientes.

## <span style="color:green">1. Descargar los datos </span>

EN ESTE PROYECTO SOLO VAMOS A NECESITAR LA BASE DE DATOS drug300.csv.

[Datos](https://github.com/jofsanchezci/Datos_Int_IA)
"""

# Importa las librerias <3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

## Define una funci칩n para extraer los datos
#DOWNLOAD_ROOT es la base del GitHub donde vamos a estar descargando las bases de datos.
DOWNLOAD_ROOT = "https://raw.githubusercontent.com/jofsanchezci/Datos_Int_IA/main/drug200.csv"
#Complementos con la direcci칩n especifica de la base de datos que queremos.


def extraer_datos(database):
    csv_path =database
    return pd.read_csv(csv_path)

# Visualiza el DataFrame
df = extraer_datos(DOWNLOAD_ROOT)
df.head()

# Obten informaci칩n de los datos.
df.info()

"""## <span style="color:green">2. An치lisis de cada Variable</span>"""

#Importa seaborn para tener gr치ficos m치s chidos
import seaborn as sns
# Analiza la edad, visualiza sus m치ximos y m칤nimos
print("Max Age:", df.Age.max())
print("Min Age:", df.Age.min())
#Gr치fica la variable
#Establece una 치rea de figsize(9,5) es decir, el tama침o de la imagen
plt.figure(figsize = (9,5))
#Crea un displot para de la edad (por ser una variable num칠rica)
sns.displot(df.Age,kde=True)

# G칠nero: cuenta cu치ntos hombres y mujeres hay
df.Sex.value_counts()

# Crea una gr치fica de barras para Presi칩n Sanguinea
plt.figure(figsize = (9,5))
sns.histplot(data=df,x="BP",hue="BP")

# Crea una gr치fica de barras para Colesterol
plt.figure(figsize = (9,5))
sns.histplot(data=df,x="Cholesterol",hue="Cholesterol")

# Crea un displot para Sodio Potasio
plt.figure(figsize = (9,5))
sns.displot(df.Na_to_K,kde=True)

# Crea una gr치fica de barras para los Medicamentos (droga) 游눍
plt.figure(figsize = (9,5))
sns.histplot(data=df,x="Drug",hue="Drug")
#Cuenta los medicamentos
df.Drug.value_counts()

"""***

## <span style="color:green">3. An치lisis de Relaci칩n entre Variables</span>
"""

## Grafica (con swarmplot) la relaci칩n entre la Edad y los Medicamentos que se les da acorde a 游눍
plt.figure(figsize = (9,5))
sns.swarmplot(x = "Drug", y = "Age",data = df)
plt.legend(df.Drug.value_counts().index)
plt.title("Edad/Medicamento")

# Grafica la relaci칩n entre el el G칠nero y los Medicamentos 游눍 que se les da
#Primero armar una tablita para poder graficarlas
df_Sex_Drug = df.groupby(["Drug","Sex"]).size().reset_index(name = "Count")
#Grafica la tablita anterior con una gr치fica de barras
plt.figure(figsize = (9,5))
sns.barplot(x = "Drug",y="Count", hue = "Sex",data = df_Sex_Drug)
plt.title("G칠nero/Medicamento")

# Grafica la relaci칩n entre la Presi칩n Sangu칤nea y los Medicamentos 游눍
df_BP_Drug = df.groupby(["Drug","BP"]).size().reset_index(name = "Count")
plt.figure(figsize = (9,5))
sns.barplot(x = "Drug",y="Count", hue = "BP",data = df_BP_Drug)
plt.title("Presi칩n Sanguinea/Medicamentos")

# Grafica (con una gr치fica de barras)nla relaci칩n entre el nivel de colesterol y los medicamentos 游눍
df_CH_Drug = df.groupby(["Drug","Cholesterol"]).size().reset_index(name = "Count")
plt.figure(figsize = (9,5))
sns.barplot(x = "Drug",y="Count", hue = "Cholesterol",data = df_CH_Drug)
plt.title("Colesterol/Medicamentos")

#Grafica (con un swarmplot) la relaci칩n entre el nivel de Sodio-Potasio y los medicamentos 游눍 que se les da
plt.figure(figsize = (9,5))
sns.swarmplot(x = "Drug", y = "Na_to_K",data = df)
plt.title("Sodio-Potasio/Medicamentos")

"""***

## <span style="color:green">4. Limpieza y Separaci칩n de Datos</span>
"""

## Utilizar LabelEncoder para procesar variables alfanum칠ricas como el sexo, BP, Colesterol, 칠tc
from sklearn.preprocessing import LabelEncoder

def label_encoder(datos_categoria):
    le = LabelEncoder()
    df[datos_categoria] = le.fit_transform(df[datos_categoria])

variables = ["Sex","BP","Cholesterol","Na_to_K","Drug"]

for l in variables:
    label_encoder(l)

df.head()

# Crear set de entrenamiento y set de prueba
x = df.drop(["Drug"],axis=1)
y = df.Drug
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42, shuffle = True)

"""El 20% de los datos, ser치n de prueba. Shuffle ser치 true. Semilla de Aleatoriedad=42

***

## <span style="color:green">5. Modelo de Clasificaci칩n Binario</span>
"""

## Crear modelo para medicamento
y_train_y = (y_train == 0)
y_test_y = (y_test == 0)

"""Empezaremos con la medicina Y porque es la m치s popular y, por ende la m치s f치cil de predecir"""

## Modelo SGD= Stochastic Gradient Descent (pr칩ximamente)
from sklearn.linear_model import SGDClassifier
sgd = SGDClassifier(random_state=42)
sgd.fit(x_train,y_train_y)
#sgd.predict([[47,1,1,0,8,0]])

#Predecir la medicina a tomar de un humano que ya sepas el resultado
sgd.predict([x_train.loc[0]]), y_train_y.loc[42]

"""游: para saber que le esta yendo bien al modelo tienen que coincidir los resultados

***

## <span style="color:green">6. Medidas de desempe침o</span>

### <span style="color:blue">6.1 Exactitud</span>
"""

# Realiza una Cross validation/K-Folds
from sklearn.model_selection import cross_val_score
cross_val_score(sgd,x_train,y_train_y,cv=3,scoring="accuracy")

"""
**cv:** n칰mero de dobleses

**scoring:** accuracy (ser치 nuestra medida de desempe침o)  """

# Modelo que nunca es Y
from sklearn.base import BaseEstimator
class NuncaC(BaseEstimator):
    def fit(self,X,y=None):
        return self
    def predict(self,X):
        return np.zeros((len(X),1),dtype=bool)

nunca_c = NuncaC()
cross_val_score(nunca_c,x_train,y_train_y,cv=3,scoring="accuracy")

"""***

### <span style="color:blue">6.2 Matriz de Confusi칩n</span>
"""

# Matriz de confusi칩n
#Importar cross_val_predict
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd,x_train,y_train_y,cv=3)
#Importar confusion_matrix
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_y,y_train_pred)

"""**Verdaderos Negativos**: esquina superior izquierda

**Falsos positivos**: esquina superior derecha

**Falsos Negativos**: esquina inferior izquierda

**Verdaderos Positivos**: esquina inferior derecha

***

### <span style="color:blue">6.3 Precision y Recall</span>
"""

#Importar precision_score y recall_score
from sklearn.metrics import precision_score, recall_score
p = precision_score(y_train_y,y_train_pred)
r = recall_score(y_train_y,y_train_pred)
p,r

#Cambiar de clasificador
#Importar RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state = 42)
rfc.fit(x_train,y_train_y)
#Hacer la matriz de confusi칩n otra vez
y_train_pred = cross_val_predict(rfc,x_train,y_train_y,cv=3)
confusion_matrix(y_train_y,y_train_pred)

#Calcular la precisi칩n y recall con el nuevo clasificador
p = precision_score(y_train_y,y_train_pred)
r = recall_score(y_train_y,y_train_pred)
p,r

#Calcular F1
from sklearn.metrics import f1_score
f1_score(y_train_y,y_train_pred)

"""***

### <span style="color:blue">6.4 Umbral Precision y Recall</span>
"""

#Puntaci칩n de un paciente aleatorio
y_score = sgd.decision_function([[47,1,1,0,8,0,0]])
y_score

#Graficar la precisi칩n y recall
y_scores = cross_val_predict(sgd,x_train,y_train_y,cv=3,method="decision_function")
#Puedes visualizar los y_scores pero no te dice nada, la gr치fica si lo har치
#Graficar la precisi칩n y recall, ahora si
from sklearn.metrics import precision_recall_curve
precisions, recalls, umbrales = precision_recall_curve(y_train_y,y_scores)
plt.plot(umbrales, precisions[:-1],"b--",label="Precisi칩n")
plt.plot(umbrales, recalls[:-1],"g-",label="Recall")
plt.legend()
plt.show()

"""El umbral te permite conocer qu칠 medida priorizar acorde a tus objetivos. Ya sea que estemos hablando de videos de youtube para ni침os 游꼸 o un sistema de seguridad 游."""

#Supon que ya lo pensaste y quer칤as un umbral  90
umbral_90 = umbrales[np.argmax(precisions >= 0.90)]
umbral_90

#Arroja la precisi칩n y recall para un umbral de 90
y_train_90 = (y_scores >= umbral_90)
p = precision_score(y_train_y,y_train_90)
r = recall_score(y_train_y,y_train_90)
p,r

"""***

### <span style="color:blue">6.5 Curva ROC</span>

Grafica Recall contra el porcentaje de Falsos Positivos
"""

#Importar roc_curve
from sklearn.metrics import roc_curve
fpr, tpr, umbrales = roc_curve(y_train_y,y_scores)

#Graficar la curva ROC
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1],[0, 1], 'k--')
plt.ylabel("True Positive Rate")
plt.xlabel("False Positive Rate")
#Poner una cuadr칤cula
plt.grid()
plt.show()

"""Un modelo perfecto se asimila a una escuadra entre la curva ROC y la l칤nea punteada porque existe una mayor 치rea bajo la curva"""

#Calcular el puntaje de la curva
from sklearn.metrics import roc_auc_score
roc_auc_score(y_train_y,y_scores)

#Compararlo con el modelo de random forest
y_forest = cross_val_predict(rfc,x_train,y_train_y,cv=3,method="predict_proba")
y_scores_forest = y_forest[:,1]

#Graficar la curva ROC y la predicci칩n de random forest
fpr_forest, tpr_forest, umbral_forest = roc_curve(y_train_y,y_scores_forest)
plt.plot(fpr, tpr, label=" SGD ROC Curve")
plt.plot(fpr_forest, tpr_forest, label=" RF ROC Curve")
plt.plot([0, 1],[0, 1], 'k--')
plt.legend()
plt.ylabel("True Positive Rate")
plt.xlabel("False Positive Rate")
plt.grid()
plt.show()

#Calcular el puntaje (치rea bajo la curva) de random forest
roc_auc_score(y_train_y,y_scores_forest)

"""## <span style="color:green">7. Clasificadores Multiclase</span>

"""

# Importar SVC=Support Vector Classifier
from sklearn.svm import SVC
svm = SVC()
svm.fit(x_train,y_train)

#Predecir a un humano aleatorio para ver que todo este funcionando bien
svm.predict([[25,0,1,0,167,1]])

#Utilizar decision_function para observar los puntajes de cada medicina
svm.decision_function([[25,0,1,0,167,1,0]])
#Decidir치 por el qu칠 tenga mayor puntaje

#Ahora, utiliza el clasificador multiclase
from sklearn.multiclass import OneVsRestClassifier
svm = OneVsRestClassifier(SVC())
svm.fit(x_train,y_train)
#Predecir a un humano ahora con este clasificador
svm.predict([[25,0,1,0,167,1]])

#Utilizar decision_function para observar los puntajes de cada medicina
svm.decision_function([[25,0,1,0,167,1,0]])

#campararlo con los datos obtenidos de sgd.fit
sgd.fit(x_train,y_train)

"""## <span style="color:green">8. Analizar Errores</span>"""

#Hacer un clasificador de random forest
rfc.fit(x_train, y_train)

#Utilizar la matriz de confusi칩n
y_train_pred = cross_val_predict(rfc, x_train, y_train, cv=3)
conf_mz = confusion_matrix(y_train,y_train_pred)
conf_mz

#utilizar ahora SGD
y_train_pred = cross_val_predict(sgd, x_train, y_train, cv=3)
conf_mz = confusion_matrix(y_train,y_train_pred)
conf_mz