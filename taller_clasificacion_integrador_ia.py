# -*- coding: utf-8 -*-
"""taller_clasificacion_integrador_ia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/jofsanchezci/b0b2ab420129b7575e18711c6c3e99bc/taller_clasificacion_integrador_ia.ipynb

#Clasificación

Proyecto de clasificación, para diagnosticar medicamenttos basándose en las caracteristicas de los pacientes.

## <span style="color:green">1. Descargar los datos </span>

EN ESTE PROYECTO SOLO VAMOS A NECESITAR LA BASE DE DATOS drug300.csv.

[Datos](https://github.com/jofsanchezci/Datos_Int_IA)
"""

# Importa las librerias <3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os

## Define una función para extraer los datos
#DOWNLOAD_ROOT es la base del GitHub donde vamos a estar descargando las bases de datos.
DOWNLOAD_ROOT = "https://raw.githubusercontent.com/jofsanchezci/Datos_Int_IA/main/drug200.csv"
#Complementos con la dirección especifica de la base de datos que queremos.


def extraer_datos(database):
    csv_path =database
    return pd.read_csv(csv_path)

# Visualiza el DataFrame
df = extraer_datos(DOWNLOAD_ROOT)
df.head()

# Obten información de los datos.
df.info()

"""## <span style="color:green">2. Análisis de cada Variable</span>"""

#Importa seaborn para tener gráficos más chidos
import seaborn as sns
# Analiza la edad, visualiza sus máximos y mínimos
print("Max Age:", df.Age.max())
print("Min Age:", df.Age.min())
#Gráfica la variable
#Establece una área de figsize(9,5) es decir, el tamaño de la imagen
plt.figure(figsize = (9,5))
#Crea un displot para de la edad (por ser una variable numérica)
sns.displot(df.Age,kde=True)

# Género: cuenta cuántos hombres y mujeres hay
df.Sex.value_counts()

# Crea una gráfica de barras para Presión Sanguinea
plt.figure(figsize = (9,5))
sns.histplot(data=df,x="BP",hue="BP")

# Crea una gráfica de barras para Colesterol
plt.figure(figsize = (9,5))
sns.histplot(data=df,x="Cholesterol",hue="Cholesterol")

# Crea un displot para Sodio Potasio
plt.figure(figsize = (9,5))
sns.displot(df.Na_to_K,kde=True)

# Crea una gráfica de barras para los Medicamentos (droga) 💊
plt.figure(figsize = (9,5))
sns.histplot(data=df,x="Drug",hue="Drug")
#Cuenta los medicamentos
df.Drug.value_counts()

"""***

## <span style="color:green">3. Análisis de Relación entre Variables</span>
"""

## Grafica (con swarmplot) la relación entre la Edad y los Medicamentos que se les da acorde a 💊
plt.figure(figsize = (9,5))
sns.swarmplot(x = "Drug", y = "Age",data = df)
plt.legend(df.Drug.value_counts().index)
plt.title("Edad/Medicamento")

# Grafica la relación entre el el Género y los Medicamentos 💊 que se les da
#Primero armar una tablita para poder graficarlas
df_Sex_Drug = df.groupby(["Drug","Sex"]).size().reset_index(name = "Count")
#Grafica la tablita anterior con una gráfica de barras
plt.figure(figsize = (9,5))
sns.barplot(x = "Drug",y="Count", hue = "Sex",data = df_Sex_Drug)
plt.title("Género/Medicamento")

# Grafica la relación entre la Presión Sanguínea y los Medicamentos 💊
df_BP_Drug = df.groupby(["Drug","BP"]).size().reset_index(name = "Count")
plt.figure(figsize = (9,5))
sns.barplot(x = "Drug",y="Count", hue = "BP",data = df_BP_Drug)
plt.title("Presión Sanguinea/Medicamentos")

# Grafica (con una gráfica de barras)nla relación entre el nivel de colesterol y los medicamentos 💊
df_CH_Drug = df.groupby(["Drug","Cholesterol"]).size().reset_index(name = "Count")
plt.figure(figsize = (9,5))
sns.barplot(x = "Drug",y="Count", hue = "Cholesterol",data = df_CH_Drug)
plt.title("Colesterol/Medicamentos")

#Grafica (con un swarmplot) la relación entre el nivel de Sodio-Potasio y los medicamentos 💊 que se les da
plt.figure(figsize = (9,5))
sns.swarmplot(x = "Drug", y = "Na_to_K",data = df)
plt.title("Sodio-Potasio/Medicamentos")

"""***

## <span style="color:green">4. Limpieza y Separación de Datos</span>
"""

## Utilizar LabelEncoder para procesar variables alfanuméricas como el sexo, BP, Colesterol, étc
from sklearn.preprocessing import LabelEncoder

def label_encoder(datos_categoria):
    le = LabelEncoder()
    df[datos_categoria] = le.fit_transform(df[datos_categoria])

variables = ["Sex","BP","Cholesterol","Na_to_K","Drug"]

for l in variables:
    label_encoder(l)

df.head()

# Crear set de entrenamiento y set de prueba
x = df.drop(["Drug"],axis=1)
y = df.Drug
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42, shuffle = True)

"""El 20% de los datos, serán de prueba. Shuffle será true. Semilla de Aleatoriedad=42

***

## <span style="color:green">5. Modelo de Clasificación Binario</span>
"""

## Crear modelo para medicamento
y_train_y = (y_train == 0)
y_test_y = (y_test == 0)

"""Empezaremos con la medicina Y porque es la más popular y, por ende la más fácil de predecir"""

## Modelo SGD= Stochastic Gradient Descent (próximamente)
from sklearn.linear_model import SGDClassifier
sgd = SGDClassifier(random_state=42)
sgd.fit(x_train,y_train_y)
#sgd.predict([[47,1,1,0,8,0]])

#Predecir la medicina a tomar de un humano que ya sepas el resultado
sgd.predict([x_train.loc[0]]), y_train_y.loc[42]

"""👀: para saber que le esta yendo bien al modelo tienen que coincidir los resultados

***

## <span style="color:green">6. Medidas de desempeño</span>

### <span style="color:blue">6.1 Exactitud</span>
"""

# Realiza una Cross validation/K-Folds
from sklearn.model_selection import cross_val_score
cross_val_score(sgd,x_train,y_train_y,cv=3,scoring="accuracy")

"""
**cv:** número de dobleses

**scoring:** accuracy (será nuestra medida de desempeño)  """

# Modelo que nunca es Y
from sklearn.base import BaseEstimator
class NuncaC(BaseEstimator):
    def fit(self,X,y=None):
        return self
    def predict(self,X):
        return np.zeros((len(X),1),dtype=bool)

nunca_c = NuncaC()
cross_val_score(nunca_c,x_train,y_train_y,cv=3,scoring="accuracy")

"""***

### <span style="color:blue">6.2 Matriz de Confusión</span>
"""

# Matriz de confusión
#Importar cross_val_predict
from sklearn.model_selection import cross_val_predict
y_train_pred = cross_val_predict(sgd,x_train,y_train_y,cv=3)
#Importar confusion_matrix
from sklearn.metrics import confusion_matrix
confusion_matrix(y_train_y,y_train_pred)

"""**Verdaderos Negativos**: esquina superior izquierda

**Falsos positivos**: esquina superior derecha

**Falsos Negativos**: esquina inferior izquierda

**Verdaderos Positivos**: esquina inferior derecha

***

### <span style="color:blue">6.3 Precision y Recall</span>
"""

#Importar precision_score y recall_score
from sklearn.metrics import precision_score, recall_score
p = precision_score(y_train_y,y_train_pred)
r = recall_score(y_train_y,y_train_pred)
p,r

#Cambiar de clasificador
#Importar RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state = 42)
rfc.fit(x_train,y_train_y)
#Hacer la matriz de confusión otra vez
y_train_pred = cross_val_predict(rfc,x_train,y_train_y,cv=3)
confusion_matrix(y_train_y,y_train_pred)

#Calcular la precisión y recall con el nuevo clasificador
p = precision_score(y_train_y,y_train_pred)
r = recall_score(y_train_y,y_train_pred)
p,r

#Calcular F1
from sklearn.metrics import f1_score
f1_score(y_train_y,y_train_pred)

"""***

### <span style="color:blue">6.4 Umbral Precision y Recall</span>
"""

#Puntación de un paciente aleatorio
y_score = sgd.decision_function([[47,1,1,0,8,0,0]])
y_score

#Graficar la precisión y recall
y_scores = cross_val_predict(sgd,x_train,y_train_y,cv=3,method="decision_function")
#Puedes visualizar los y_scores pero no te dice nada, la gráfica si lo hará
#Graficar la precisión y recall, ahora si
from sklearn.metrics import precision_recall_curve
precisions, recalls, umbrales = precision_recall_curve(y_train_y,y_scores)
plt.plot(umbrales, precisions[:-1],"b--",label="Precisión")
plt.plot(umbrales, recalls[:-1],"g-",label="Recall")
plt.legend()
plt.show()

"""El umbral te permite conocer qué medida priorizar acorde a tus objetivos. Ya sea que estemos hablando de videos de youtube para niños 🍭 o un sistema de seguridad 🔒."""

#Supon que ya lo pensaste y querías un umbral  90
umbral_90 = umbrales[np.argmax(precisions >= 0.90)]
umbral_90

#Arroja la precisión y recall para un umbral de 90
y_train_90 = (y_scores >= umbral_90)
p = precision_score(y_train_y,y_train_90)
r = recall_score(y_train_y,y_train_90)
p,r

"""***

### <span style="color:blue">6.5 Curva ROC</span>

Grafica Recall contra el porcentaje de Falsos Positivos
"""

#Importar roc_curve
from sklearn.metrics import roc_curve
fpr, tpr, umbrales = roc_curve(y_train_y,y_scores)

#Graficar la curva ROC
plt.plot(fpr, tpr, label="ROC Curve")
plt.plot([0, 1],[0, 1], 'k--')
plt.ylabel("True Positive Rate")
plt.xlabel("False Positive Rate")
#Poner una cuadrícula
plt.grid()
plt.show()

"""Un modelo perfecto se asimila a una escuadra entre la curva ROC y la línea punteada porque existe una mayor área bajo la curva"""

#Calcular el puntaje de la curva
from sklearn.metrics import roc_auc_score
roc_auc_score(y_train_y,y_scores)

#Compararlo con el modelo de random forest
y_forest = cross_val_predict(rfc,x_train,y_train_y,cv=3,method="predict_proba")
y_scores_forest = y_forest[:,1]

#Graficar la curva ROC y la predicción de random forest
fpr_forest, tpr_forest, umbral_forest = roc_curve(y_train_y,y_scores_forest)
plt.plot(fpr, tpr, label=" SGD ROC Curve")
plt.plot(fpr_forest, tpr_forest, label=" RF ROC Curve")
plt.plot([0, 1],[0, 1], 'k--')
plt.legend()
plt.ylabel("True Positive Rate")
plt.xlabel("False Positive Rate")
plt.grid()
plt.show()

#Calcular el puntaje (área bajo la curva) de random forest
roc_auc_score(y_train_y,y_scores_forest)

"""## <span style="color:green">7. Clasificadores Multiclase</span>

"""

# Importar SVC=Support Vector Classifier
from sklearn.svm import SVC
svm = SVC()
svm.fit(x_train,y_train)

#Predecir a un humano aleatorio para ver que todo este funcionando bien
svm.predict([[25,0,1,0,167,1]])

#Utilizar decision_function para observar los puntajes de cada medicina
svm.decision_function([[25,0,1,0,167,1,0]])
#Decidirá por el qué tenga mayor puntaje

#Ahora, utiliza el clasificador multiclase
from sklearn.multiclass import OneVsRestClassifier
svm = OneVsRestClassifier(SVC())
svm.fit(x_train,y_train)
#Predecir a un humano ahora con este clasificador
svm.predict([[25,0,1,0,167,1]])

#Utilizar decision_function para observar los puntajes de cada medicina
svm.decision_function([[25,0,1,0,167,1,0]])

#campararlo con los datos obtenidos de sgd.fit
sgd.fit(x_train,y_train)

"""## <span style="color:green">8. Analizar Errores</span>"""

#Hacer un clasificador de random forest
rfc.fit(x_train, y_train)

#Utilizar la matriz de confusión
y_train_pred = cross_val_predict(rfc, x_train, y_train, cv=3)
conf_mz = confusion_matrix(y_train,y_train_pred)
conf_mz

#utilizar ahora SGD
y_train_pred = cross_val_predict(sgd, x_train, y_train, cv=3)
conf_mz = confusion_matrix(y_train,y_train_pred)
conf_mz